.. _quick_start:
.. title:: scikit-plots: Machine Learning Visualization with Python

===========
Quick Start
===========

A quick plot with scikit-plots.

A Simple Example
----------------

For our quick example, let's show how well a Random Forest can classify the digits dataset bundled with Scikit-learn. A popular way to evaluate a classifier's performance is by viewing its confusion matrix.

Before we begin plotting, we'll need to import the following for Scikit-plots::

    >>> import matplotlib.pyplot as plt

:mod:`matplotlib.pyplot` is used by Matplotlib to make plotting work like it does in MATLAB and deals with things like axes, figures, and subplots. But don't worry. Unless you're an advanced user, you won't need to understand any of that while using Scikit-plots. All you need to remember is that we use the :func:`matplotlib.pyplot.show` function to show any plots generated by Scikit-plots.

Let's begin by generating our sample digits dataset::

    >>> from sklearn.datasets import load_digits
    >>> X, y = load_digits(return_X_y=True)

Here, ``X`` and ``y`` contain the features and labels of our classification dataset, respectively.

We'll proceed by creating an instance of a RandomForestClassifier object from Scikit-learn with some initial parameters::

    >>> from sklearn.ensemble import RandomForestClassifier
    >>> clf = RandomForestClassifier(n_estimators=5, max_depth=5, random_state=1)

Let's use :func:`sklearn.model_selection.cross_val_predict` to generate predicted labels on our dataset::

    >>> from sklearn.model_selection import cross_val_predict
    >>> y_pred = cross_val_predict(clf, X, y)

For those not familiar with what :func:`cross_val_predict` does, it generates cross-validated estimates for each sample point in our dataset. Comparing the cross-validated estimates with the true labels, we'll be able to get evaluation metrics such as accuracy, precision, recall, and in our case, the confusion matrix.

To plot and show our confusion matrix, we'll use the function :func:`~scikitplot.metrics.plot_classifier_eval`, passing it both the true labels and predicted labels. Finally, to show our plot, we'll call ``plt.show()`` optional.

    >>> import scikitplot as skplt
    >>> fig1 = skplt.metrics.plot_classifier_eval(
    >>>     y, y_pred, 
    >>>     labels=np.unique(y),
    >>>     figsize=(8, 2),
    >>>     title='',
    >>> );

.. image:: _static/quickstart_plot_classifier_eval.png
   :align: center
   :alt: Classification Report with Confusion Matrix

And that's it! A quick glance of our confusion matrix shows that our classifier isn't doing so well with identifying the digits 1, 8, and 9. Hmm. Perhaps a bit more tweaking of our Random Forest's hyperparameters is in order.

One More Example
----------------

Finally, let's show an example wherein we *don't* use Scikit-learn.

Here's a quick example to generate the precision-recall curves of a Keras classifier on a sample dataset.

    >>> import scikitplot as skplt
    >>> # This is a Keras classifier. We'll generate probabilities on the test set.
    >>> keras_clf.fit(X_train, y_train, batch_size=64, nb_epoch=10, verbose=2)
    >>> probas = keras_clf.predict_proba(X_test, batch_size=64)
    >>> # Now plot.
    >>> skplt.metrics.plot_precision_recall(y_test, probas);

.. image:: _static/quickstart_plot_precision_recall.png
   :align: center
   :alt: Precision Recall Curves

And again, that's it! As in the example above, all we needed to do was pass the ground truth labels and predicted probabilities to :func:`~scikitplot.metrics.plot_precision_recall_curve` to generate the precision-recall curves. This means you can use literally any classifier you want to generate the precision-recall curves, from Keras classifiers to NLTK Naive Bayes to XGBoost, as long as you pass in the predicted probabilities in the correct format.

Now what?
---------

The recommended way to start using Scikit-plot is to just go through the documentation for the various modules and choose which plots you think would be useful for your work.

Happy plotting!